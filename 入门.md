# 入门

## 引言

Apache Kafka®是一个分布式流平台。这到底是什么意思呢？
流平台具有三个关键功能：

* 发布和订阅记录流(streams of records)，类似于消息队列或企业消息传递系统。
* 以容错的持久方式存储记录流。
* 处理记录流。

Kafka通常用于两大类应用程序：

* 建立实时流数据管道(pipeline)，可靠地在应用程序之间获取数据。
* 构建实时流应用程序以转换或响应数据流。
* 要了解Kafka如何执行这些操作，让我们从头开始深入研究Kafka的功能。

首先几个概念：

* Kafka在一个或多个的服务器上作为集群运行，可以跨越多个数据中心。
* Kafka集群将记录流存储在叫做topic的一组分类中。
* 每个记录由一个键、一个值和一个时间戳组成。

Kafka具有四个核心API：

* Producer API，应用程序发布记录流至一个或多个Kafka topic。
* Consumer API，应用程序订阅一个或多个topic，并处理所产生的数据流。
* Streams API，应用程序充当stream processor，从至少一个topic消费input stream，生产一个output stream到一个或多个output topic，有效地将input stream转化为output stream。
* Connector API，以可复用的生产者或消费者连接至Kafka topic，用以连接应用程序或数据系统。例如，关系数据库的连接器可能会捕获对表的所有更改。

在Kafka中，客户端和服务器之间的通信是通过简单、高性能、语言无关的TCP协议完成的。该协议已版本化，并与旧版本保持向后兼容。我们为Kafka提供了Java客户端，客户端还支持了更多语言。

### topic和日志

让我们首先深入Kafka为记录流提供的核心抽象——topic。
topic是记录发布的分类名称或订阅来源（category or feed）。Kafka中的topic始终是多用户的；也就是说，一个topic可以有零个、一个或多个消费者来订阅写入该topic的数据。
对于每个topic，Kafka集群都会维护一个分区日志，如下所示：

**Topic解剖图**
每个分区都是有序的、不变的记录（record）序列，这些记录连续地追加到结构化的提交日志中。每个分区中的记录都分配有一个称为offset的顺序ID号，该ID 唯一地标识分区中的每个记录。
Kafka集群持久地保留所有已发布的记录（无论是否已消费它们），持久期限是可配置的。例如，如果将保留策略设置为两天，则在发布记录后的两天内，该记录可供消费，之后将被丢弃并释放空间。Kafka的性能相对于数据大小实际上是稳定的，因此长时间存储数据不是问题。

实际上，每个消费者保留的唯一元数据是该消费者在日志中的offset或位置。此offset由消费者控制：通常，消费者在读取record时会线性地推进其offset，但是实际上，由于位置是由消费者控制的，因此它可以按喜欢的任何顺序消费记录。例如，消费者可以重置到较早的offset以重新处理过去的数据，或者跳到最近的记录并从"现在"开始消费。
这些功能的组合意味着Kafka的消费者成本非常低廉——他们来来去去对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具"tail"来获取任何topic的尾部内容，而无需更改任何其他消费者所消费的内容。
日志中的分区有几个用途。首先，它们允许日志扩展到超出单个服务器上可容纳的大小。每个单独的分区都必须适合托管该分区的服务器，但是一个topic可能有很多分区，因此它可以处理任意数量的数据。其次，它们充当并发单元——稍后再谈这个。

### 分布式分配

日志的分区分布在Kafka集群的服务器上，每个服务器处理数据并共享分区。每个分区都在服务器之间复制，以实现容错功能。
每个分区都有一个充当"leader"的服务器和零个或多个充当"follower"的服务器。leader处理对分区的所有读写请求，而follower则被动地复制leader。如果leader失败，则follower之一将自动成为新leader。每台服务器都是分区的leader或follower，因此负载在集群中得到很好的平衡。

### 地理复制

Kafka MirrorMaker为您的集群提供地理复制支持。使用MirrorMaker，可以在多个数据中心或cloud域之间复制消息。您可以在主动/被动方案中使用它进行备份和恢复。或在主动/主动方案中将数据放置在离您的用户更近的位置，或支持对数据位置的要求。

### 生产者

生产者将数据发布到topic。生产者负责将record分配给topic中的分区。可以循环完成此操作，只是为了负载平衡，也可以根据某些语义做分区（例如基于记录中的某些key）进行此操作，一秒钟就可以了解有关分区的信息！

### 消费者

消费者使用消费者组（consumer group）名称标记自己，并且发布到topic的每条记录都会传递到每个订阅消费者组中的一个消费者实例。消费者实例可以在独立的进程或独立的机器上。
如果所有消费者实例都具有相同的消费者组，那么将在这些消费者实例上有效地平衡record。
如果所有消费者实例具有不同的消费者组，则每条记录将广播到所有消费者。

一个由两台服务器组成的Kafka集群，其中包含四个分区（P0-P3），带有两个消费者组。消费者组A有两个消费者实例，组B有四个。
但是，更常见的是，我们发现topic具有少量的消费者组，每个"订阅的业务分类"一个。每个组均由许多消费者实例组成，以实现可伸缩性和容错能力。这无非就是发布-订阅语义，其中订阅者是消费者的集群而不是单个进程。
Kafka中实现消费的方式是通过在消费者实例上划分日志中的分区，以便每个消费者实例在任何时间点都是分区"平公份额"的排他消费者。在组内维护成员的过程由Kafka协议动态处理。如果新实例加入该组，它们将接管该组其他成员的某些分区；如果实例消亡，则其分区将分配给其余实例。
Kafka只提供了分区内记录的总顺序，而不是一个topic的不同分区之间的记录顺序。对于大多数应用程序，按分区排序以及按键对数据进行分区的能力就足够了。但是，如果您需要总记录的顺序，则可以通过只有一个分区的topic来实现，这将意味着每个消费者组只有一个消费者进程。

### Multi-tenancy（多租户）

多租户，多租户技术（英语：multi-tenancy technology）或称多重租赁技术，是一种软件架构技术，它是在探讨与实现如何在多用户的环境下共用相同的系统或程序组件，并且仍可确保各用户间数据的隔离性。
您可以将Kafka部署为多租户方案。通过启用多租户配置哪些topic可以生产或消费数据。配额也有操作支持。管理员可以对请求定义和实施配额，以控制客户端使用的broker资源。有关更多信息，请参阅安全性文档。

### 保证

high-level Kafka提供以下保证：

* 生产者发送到指定topic分区的消息将按其发送顺序追加。也就是说，如果记录M1是与记录M2由相同的生产者发送的，并且首先发送M1，则M1的offset将小于M2，并在日志中更早地出现。
* 消费者实例按记录在日志中的存储顺序查看记录。
* 对于复制因子为N的topic，我们最多可以容忍N-1个服务器故障，而不会丢失提交给日志的记录。
  在文档的设计部分中提供了有关这些保证的更多详细信息。

### Kafka作为消息传递系统

**Kafka的流概念与传统的企业消息传递系统相比如何？**
传统上，消息传递具有两种模型：queuing和publish-subscribe。在队列中，一组消费者可以从服务器读取数据，并且每条记录都进入其中一个消费者；在publish-subscribe中记录广播给所有消费者。这两个模型中的每一个都有优点和缺点。队列的优势在于，它允许您将数据划分到多个消费者实例上，从而扩展处理量。不幸的是，队列不是多用户的，一次读取则数据弹出。发布－订阅允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，因此无法弹性处理。
Kafka的消费组概括了这两个概念。与队列一样，消费者组允许您将处理划分为一组进程（消费者组的成员）。与发布订阅一样，Kafka允许您将消息广播到多个消费者组。
Kafka模型的优势在于，每个topic都具有这些属性——可以扩展处理范围，并且是多订阅者——无需选择其中一个。
与传统的消息传递系统相比，Kafka还具有更强的顺序保证。
传统队列将记录按顺序保留在服务器上，如果多个消费者从队列中消费，则服务器将按记录的存储顺序分发记录。但是，尽管服务器按顺序分发记录，这些记录是异步传递给消费者的，因此它们可能会在不同的消费者上无序到达。这实际上意味着在并行消费的情况下会丢失记录的顺序。消息传递系统常通过"专用消费者"的概念来解决此问题，该概念仅允许一个进程从队列中消费，但是，这当然意味着在处理中没有并行。
Kafka做得更好。通过在topic内具有并行性（即分区）的概念，Kafka能够在用户进程池中提供排序保证和负载均衡。这是通过将topic中的分区分配给消费者组中的消费者来实现的，以便每个分区都由组中的一个消费者完全消费。通过这样做，我们确保消费者是该分区的唯一读取者，并按顺序消费数据。由于存在许多分区，因此仍然可以平衡许多消费者实例上的负载。但是请注意，一个消费者组中的消费者实例数不能超过分区数。

### Kafka作为存储系统

任何发布与消费无关的消息队列都充当了消息的存储系统。Kafka的不同之处在于它是一个非常好的存储系统。
写入Kafka的数据将写入磁盘并进行复制以实现容错功能。Kafka允许生产者等待确认（acknowledgement），直到完全复制并确保持久化才算一笔完整写入，即使写入了失败的服务器。
Kafka的磁盘结构可以良好地扩展使用——无论服务器上有50 KB还是50 TB的持久数据，Kafka的性能都一样。
这么认真对待存储的方式加上允许客户端控制其读取位置，您可以将Kafka视为一种专用于高性能、低延迟提交日志的存储、复制和扩展的专用分布式文件系统。
有关Kafka的提交日志存储和复制设计的详细信息，请阅读此页面。

### Kafka用于流处理

仅仅读取、写入和存储数据流是不够的，目的是实现对流的实时处理。
在Kafka中，流processor是指从topic输入中获取连续数据流，对该输入进行一些处理并生成连续数据流然后输出topic的任何东西。
例如，零售应用程序可以接受销售和发货的输入流，并根据这些数据计算出重新订购和价格调整的输出流。
可以直接使用生产者和消费者API进行简单处理。但是，对于更复杂的转换，Kafka提供了完全集成的Streams API。这允许对应用程序对琐碎处理执行构建，这些构建将流聚合计算或将流连接在一起。
该功能有助于解决此类应用程序所面临的难题，如：处理无序数据、在代码更改时重新处理输入、执行状态计算等。
Streams API建立在Kafka提供的核心之上：它使用生产者和消费者API作为输入，使用Kafka进行状态存储，并使用相同的组机制来实现流processor实例之间的容错。

### 拼凑在一起

消息传递、存储和流处理的这种组合看似不寻常，但这对于Kafka作为流平台的角色而言至关重要。
像HDFS这样的分布式文件系统允许存储静态文件以进行批处理。实际上，像这样的系统可以存储和处理过去的历史数据。
传统的企业消息传递系统允许处理将来的消息，这些消息将在您订阅后到达。以这种方式构建的应用程序会在将来的数据到达时对其进行处理。
Kafka结合了这两项功能，将Kafka用作流应用程序平台和流数据管道平台而言，这种结合至关重要。
通过结合存储和低延迟订阅，流应用程序可以以相同的方式处理过去和将来的数据。也就是说，单个应用程序可以处理历史的、存储的数据，但又不会在最后一条记录到达时结束，而是可以在未来数据到达时继续处理。这是流处理的通用概念，它包含了批处理、消息驱动的应用程序。
同样，对于流数据管道，对实时事件的订阅组合使得可以将Kafka用于非常低延迟的管道。存储数据的可靠能力保证了关键数据必须传输，或者定期加载数据，或者与长时间停机进行维护的脱机系统集成。流处理设备保证数据到达时就进行转换。
有关Kafka提供的保证、API和功能的更多信息，请参阅本文档的其余部分。

